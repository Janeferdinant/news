{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Fake News Detection with NLP, ACO, and BERT\n",
    "\n",
    "This notebook implements an advanced fake news detection pipeline on a synthetic dataset of 20,000 news articles. Features:\n",
    "- **EDA**: Missing values, label/category distribution, word clouds, sentiment analysis.\n",
    "- **Preprocessing**: Text cleaning, TF-IDF, feature engineering (text length, sentiment).\n",
    "- **Feature Selection**: Embedded-Filter Ant Colony Optimization (ACO) with clustering-based mutual information.\n",
    "- **Models**: Logistic Regression, XGBoost, and BERT (DistilBERT for efficiency).\n",
    "- **Outputs**: Plotly JSON for interactive reading card integration.\n",
    "\n",
    "**Dataset**: `/kaggle/input/fake-news-dataset/fake_news_dataset.csv` (20,000 rows, 7 columns, ~5% missing values).\n",
    "\n",
    "**JNTUK AI Course**: Unit 3 (ML Basics), CO2 (apply ML/NLP, PO3), CO4 (evaluate models, PO4).\n",
    "\n",
    "**Abstract**: Implements Embedded-Filter ACO with clustering-based MI for text feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from xgboost import XGBClassifier\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import json\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('/kaggle/input/fake-news-dataset/fake_news_dataset.csv')\n",
    "\n",
    "# Display basic info\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumns and Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check missing values\n",
    "missing = df.isnull().sum() / len(df) * 100\n",
    "print(\"\\nMissing Values (%):\")\n",
    "print(missing)\n",
    "\n",
    "# Visualize missing values\n",
    "fig = px.bar(x=missing.index, y=missing.values, title=\"Missing Values by Column (%)\",\n",
    "             labels={'x': 'Column', 'y': 'Percentage'}, color_discrete_sequence=['#2563eb'])\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "# Label distribution\n",
    "label_counts = df['label'].value_counts()\n",
    "fig = px.pie(values=label_counts.values, names=label_counts.index,\n",
    "             title=\"Label Distribution (Real vs. Fake)\", color_discrete_sequence=['#2563eb', '#ff007a'])\n",
    "fig.show()\n",
    "\n",
    "# Category distribution\n",
    "category_counts = df['category'].value_counts()\n",
    "fig = px.bar(x=category_counts.index, y=category_counts.values,\n",
    "             title=\"Article Categories\", labels={'x': 'Category', 'y': 'Count'},\n",
    "             color_discrete_sequence=['#2563eb'])\n",
    "fig.show()\n",
    "\n",
    "# Sentiment distribution\n",
    "df['sentiment'] = df['text'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "fig = px.histogram(df, x='sentiment', color='label', nbins=50,\n",
    "                   title=\"Sentiment Distribution by Label\", barmode='overlay',\n",
    "                   color_discrete_sequence=['#2563eb', '#ff007a'])\n",
    "fig.show()\n",
    "\n",
    "# Word clouds\n",
    "real_text = ' '.join(df[df['label'] == 'real']['text'].dropna())\n",
    "fake_text = ' '.join(df[df['label'] == 'fake']['text'].dropna())\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(real_text)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.title('Real News Word Cloud')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(fake_text)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.title('Fake News Word Cloud')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess Data and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "df['source'] = df['source'].fillna('Unknown')\n",
    "df['author'] = df['author'].fillna('Unknown')\n",
    "df['text'] = df['text'].fillna('')\n",
    "df['title'] = df['title'].fillna('')\n",
    "\n",
    "# Combine title and text\n",
    "df['content'] = df['title'] + ' ' + df['text']\n",
    "\n",
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply text cleaning\n",
    "df['clean_content'] = df['content'].apply(clean_text)\n",
    "\n",
    "# Feature engineering\n",
    "df['text_length'] = df['text'].apply(lambda x: len(x.split()))\n",
    "df['title_length'] = df['title'].apply(lambda x: len(x.split()))\n",
    "df['sentiment'] = df['text'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "\n",
    "# Encode labels\n",
    "df['label_encoded'] = df['label'].map({'real': 1, 'fake': 0})\n",
    "\n",
    "# Correlation analysis\n",
    "corr = df[['text_length', 'title_length', 'sentiment', 'label_encoded']].corr()\n",
    "fig = px.imshow(corr, text_auto=True, title=\"Correlation Matrix\",\n",
    "                color_continuous_scale='Blues')\n",
    "fig.show()\n",
    "\n",
    "# Verify preprocessing\n",
    "print(\"\\nSample Cleaned Content:\")\n",
    "print(df['clean_content'].iloc[0][:200], '...')\n",
    "print(\"\\nFeature Engineered Columns:\")\n",
    "print(df[['text_length', 'title_length', 'sentiment']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TF-IDF Vectorization and Feature Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_text = vectorizer.fit_transform(df['clean_content']).toarray()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Combine TF-IDF with engineered features\n",
    "X_engineered = df[['text_length', 'title_length', 'sentiment']].values\n",
    "X = np.hstack((X_text, X_engineered))\n",
    "feature_names = np.concatenate((feature_names, ['text_length', 'title_length', 'sentiment']))\n",
    "y = df['label_encoded']\n",
    "\n",
    "print(\"\\nFeature Matrix Shape:\", X.shape)\n",
    "print(\"Sample Features:\", feature_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Embedded-Filter ACO Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering-based mutual information\n",
    "def clustering_based_mi(X, y, n_clusters=3):\n",
    "    mi_scores = []\n",
    "    for i in range(X.shape[1]):\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        clusters = kmeans.fit_predict(X[:, [i]])\n",
    "        mi = mutual_info_classif(clusters.reshape(-1, 1), y, random_state=42)[0]\n",
    "        mi_scores.append(mi)\n",
    "    return np.array(mi_scores)\n",
    "\n",
    "# Enhanced ACO for feature selection\n",
    "def aco_feature_selection(X, y, mi_scores, n_ants=15, n_iterations=30, evaporation_rate=0.4, max_features=200):\n",
    "    n_features = X.shape[1]\n",
    "    pheromones = np.ones(n_features) * 0.1\n",
    "    best_subset = None\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        subsets = []\n",
    "        for _ in range(n_ants):\n",
    "            prob = pheromones * mi_scores\n",
    "            prob = np.clip(prob / prob.sum(), 0, 1)\n",
    "            n_select = np.random.randint(50, max_features + 1)\n",
    "            subset = np.random.choice(n_features, size=n_select, p=prob, replace=False)\n",
    "            subsets.append(subset)\n",
    "        \n",
    "        for subset in subsets:\n",
    "            X_subset = X[:, subset]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_subset, y, test_size=0.2, random_state=42)\n",
    "            model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "            accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "            \n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_subset = subset\n",
    "            \n",
    "            pheromones *= (1 - evaporation_rate)\n",
    "            pheromones[np.array(subset)] += accuracy * (max_features / len(subset))\n",
    "    \n",
    "    return best_subset, best_accuracy\n",
    "\n",
    "# Compute MI scores\n",
    "mi_scores = clustering_based_mi(X, y)\n",
    "\n",
    "# Run ACO\n",
    "selected_indices, aco_accuracy = aco_feature_selection(X, y, mi_scores, max_features=200)\n",
    "selected_features = feature_names[selected_indices]\n",
    "print(\"\\nACO Selected Features (Top 10):\")\n",
    "print(selected_features[:10])\n",
    "print(\"ACO Preliminary Accuracy:\", aco_accuracy)\n",
    "\n",
    "# Update X with selected features\n",
    "X_selected = X[:, selected_indices]\n",
    "\n",
    "# Save MI scores plot as JSON\n",
    "mi_selected = mi_scores[selected_indices]\n",
    "fig = px.bar(x=selected_features[:20], y=mi_selected[:20],\n",
    "             title=\"Top 20 Selected Features by MI Score\",\n",
    "             labels={'x': 'Feature', 'y': 'MI Score'}, color_discrete_sequence=['#2563eb'])\n",
    "with open('/kaggle/working/mi_scores.json', 'w') as f:\n",
    "    json.dump({'data': [trace.__dict__ for trace in fig.data], 'layout': fig.layout.__dict__}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train and Evaluate Models (Logistic Regression, XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "lr_report = classification_report(y_test, lr_pred, target_names=['Fake', 'Real'])\n",
    "\n",
    "print(\"\\nLogistic Regression Performance:\")\n",
    "print(\"Accuracy:\", lr_accuracy)\n",
    "print(\"Classification Report:\\n\", lr_report)\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_pred)\n",
    "xgb_report = classification_report(y_test, xgb_pred, target_names=['Fake', 'Real'])\n",
    "\n",
    "print(\"\\nXGBoost Performance:\")\n",
    "print(\"Accuracy:\", xgb_accuracy)\n",
    "print(\"Classification Report:\\n\", xgb_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. BERT Model (DistilBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset for BERT\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts.iloc[idx])\n",
    "        label = self.labels.iloc[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Prepare BERT data\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['clean_content'], df['label_encoded'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = NewsDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = NewsDataset(test_texts, test_labels, tokenizer)\n",
    "\n",
    "# BERT model\n",
    "bert_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/kaggle/working/bert_results',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='/kaggle/working/bert_logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=bert_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "trainer.train()\n",
    "bert_results = trainer.evaluate()\n",
    "bert_accuracy = bert_results['eval_accuracy'] if 'eval_accuracy' in bert_results else 0\n",
    "\n",
    "print(\"\\nBERT (DistilBERT) Performance:\")\n",
    "print(\"Accuracy:\", bert_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare Models and Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "fig = px.bar(x=['Logistic Regression', 'XGBoost', 'BERT'],\n",
    "             y=[lr_accuracy, xgb_accuracy, bert_accuracy],\n",
    "             title=\"Model Accuracy Comparison\", labels={'x': 'Model', 'y': 'Accuracy'},\n",
    "             color_discrete_sequence=['#2563eb'])\n",
    "fig.show()\n",
    "\n",
    "# Save comparison plot as JSON\n",
    "with open('/kaggle/working/model_comparison.json', 'w') as f:\n",
    "    json.dump({'data': [trace.__dict__ for trace in fig.data], 'layout': fig.layout.__dict__}, f)\n",
    "\n",
    "# Save models and vectorizer\n",
    "joblib.dump(lr_model, '/kaggle/working/fake_news_lr_model.pkl')\n",
    "joblib.dump(xgb_model, '/kaggle/working/fake_news_xgb_model.pkl')\n",
    "joblib.dump(vectorizer, '/kaggle/working/tfidf_vectorizer.pkl')\n",
    "joblib.dump(selected_indices, '/kaggle/working/selected_indices.pkl')\n",
    "trainer.save_model('/kaggle/working/bert_model')\n",
    "\n",
    "# Save selected features\n",
    "with open('/kaggle/working/selected_features.txt', 'w') as f:\n",
    "    f.write('\\n'.join(selected_features))\n",
    "\n",
    "print(\"Models, vectorizer, and outputs saved to /kaggle/working/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
